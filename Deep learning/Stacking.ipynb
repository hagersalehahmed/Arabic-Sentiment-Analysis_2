{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4243,
     "status": "ok",
     "timestamp": 1655024682004,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "nGtm8p64fDnk",
    "outputId": "b4a857ce-d274-40ca-9020-e016ebded6b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3793,
     "status": "ok",
     "timestamp": 1655024685792,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "gT-1aT9-zMS-",
    "outputId": "41e9bf1a-11bf-483e-cf12-274fc769539c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hager\\AppData\\Local\\Temp/ipykernel_10976/1235258861.py:37: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import HyperModel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "le = LabelEncoder() \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.models import Sequential\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,GlobalMaxPooling1D\n",
    "\n",
    "from keras import backend as K\n",
    "from kerastuner import HyperModel\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from numpy import dstack\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 214706,
     "status": "ok",
     "timestamp": 1655024900492,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "yKPDprXofrYb",
    "outputId": "7a07a597-3f61-4c02-d486-22e2235f8580"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43955,
     "status": "ok",
     "timestamp": 1655024944438,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "7ywmF4mMQN_3"
   },
   "outputs": [],
   "source": [
    "word2vemodel = gensim.models.Word2Vec.load('/content/drive/MyDrive/ArabicSentimentHager/full_grams_cbow_300_twitter.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1119,
     "status": "ok",
     "timestamp": 1655024945547,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "vhwHC0qlZVJA",
    "outputId": "d0a55091-b9e1-4daf-ad6f-ff4c39988380"
   },
   "outputs": [],
   "source": [
    "#read train dataset\n",
    "train= pd.read_csv('/content/drive/MyDrive/ArabicSentimentHager/paper2/Deep/sg/dataset1/Training_Main-AHS.csv',encoding='utf-8')\n",
    "train=train.dropna()\n",
    "\n",
    "y_train1 = train.label                           \n",
    "X_train= train.drop('label',axis = 1 )\n",
    "\n",
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1655024946000,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "2Kv_uwaZZW9t",
    "outputId": "804e1f1a-6fed-4ecf-c103-d7f8e94342b8"
   },
   "outputs": [],
   "source": [
    "#read testing dataset\n",
    "test= pd.read_csv('/content/drive/MyDrive/ArabicSentimentHager/paper2/Deep/sg/dataset1/Testing_Main-AHS.csv',encoding='utf-8')\n",
    "test=test.dropna()\n",
    "\n",
    "y_test1= test.label                           \n",
    "X_test= test.drop('label',axis = 1 )\n",
    "test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1655024946001,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "NTNA_GaXfrbR"
   },
   "outputs": [],
   "source": [
    "#convert label to categorical\n",
    "encoder_train_y = LabelEncoder()\n",
    "y_train= encoder_train_y.fit_transform(y_train1)\n",
    "y_train_categorical = np_utils.to_categorical(y_train)\n",
    "\n",
    "encoder_test_y = LabelEncoder()\n",
    "y_test = encoder_test_y.fit_transform(y_test1)\n",
    "y_test_categorical=np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1655024946273,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "Qh9Xww-Ufrgp",
    "outputId": "51330904-4962-497c-b207-a54c9b4767f5"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 140  # cut texts after this number of words (among top max_features most common words)\n",
    "BATCH_SIZE = 2000\n",
    "MAX_NUM_WORDS = 200000\n",
    "EMBEDDING_DIM = 300\n",
    "epoch=20\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(X_train['text'])\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train['text'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "padded_train = pad_sequences(sequences=train_sequences, maxlen=MAX_LEN)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test['text'])\n",
    "padded_test = pad_sequences(sequences=test_sequences, maxlen=MAX_LEN)\n",
    "\n",
    "print('Total unique tokens generated: ',len(word_index))\n",
    "print('Shape of padded train tensor: ', padded_train.shape)\n",
    "print('Shape of padded test tensor: ', padded_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1655024946274,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "fuQ0p_N6f6bg"
   },
   "outputs": [],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(word_index))\n",
    "word_embedding_matrix = np.zeros((num_words + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, index in word_index.items():\n",
    "    if index > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    # embedding_vector = model[word]\n",
    "    #word = clean_str(word)\n",
    "    if word not in word2vemodel.wv:\n",
    "        embedding_vector = None\n",
    "    else:\n",
    "        embedding_vector = word2vemodel.wv[word]\n",
    "    if embedding_vector is not None:\n",
    "        word_embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1655024946275,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "ZAjMJ_UufDny"
   },
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10135,
     "status": "ok",
     "timestamp": 1655024956404,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "k-zXiwlBfDnz",
    "outputId": "b7739c34-f47b-4dab-8751-7dab2269d8bd"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_DEEPCNN= load_model('/content/drive/MyDrive/ArabicSentimentHager/paper2/Deep/CBOW/dataset1/model/DeepCNN.h5', custom_objects={'f1_m': f1_m,  'precision_m': precision_m, 'recall_m': recall_m} )\n",
    "model_CNN_LSTM= load_model('/content/drive/MyDrive/ArabicSentimentHager/paper2/Deep/CBOW/dataset1/model/CNNLSTM.h5', custom_objects={'f1_m': f1_m,  'precision_m': precision_m, 'recall_m': recall_m} )\n",
    "model_CNN_GRU= load_model('/content/drive/MyDrive/ArabicSentimentHager/paper2/Deep/CBOW/dataset1/model/CNN_GRU.h5', custom_objects={'f1_m': f1_m,  'precision_m': precision_m, 'recall_m': recall_m} )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1655024956405,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "U9Rz7ZxlfDnz"
   },
   "outputs": [],
   "source": [
    "members={'DEEPCNN':model_DEEPCNN,'CNN_LSTM':model_CNN_LSTM, 'CNN_GRU':model_CNN_GRU}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1655024956406,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "sH9-s7sGfDn0",
    "outputId": "0668996d-3a39-43fa-cd35-9536c6f0c661"
   },
   "outputs": [],
   "source": [
    "members['DEEPCNN'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1655024956407,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "g87kOdFSSGki",
    "outputId": "b3c6673f-7b88-43e9-a8d6-d9971ab1e544"
   },
   "outputs": [],
   "source": [
    "'''for key in members:\n",
    "    for i in range(0, len(members[key].layers)-1):\n",
    "        members[key].layers[i].trainable = False'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1655024956408,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "Q1XA96kEfDn0"
   },
   "outputs": [],
   "source": [
    "epoch=30\n",
    "BATCH_SIZE=1000\n",
    "\n",
    "# create stacked model input dataset as outputs from the ensemble\n",
    "def stacked_dataset(members,padded_train, padded_test, y_train_categorical,stack_Train, stack_Test,BATCH_SIZE,epoch):\n",
    "    for key in members:     \n",
    "        \n",
    "        if key=='DEEPCNN':\n",
    "            members['DEEPCNN'].fit(padded_train, y_train_categorical, epochs=epoch, batch_size=BATCH_SIZE)\n",
    "            yhat1 = members['DEEPCNN'].predict(padded_train, verbose=0)\n",
    "            yhat2 = members['DEEPCNN'].predict(padded_test, verbose=0)\n",
    "            \n",
    "        elif key=='CNN_LSTM':\n",
    "            members['CNN_LSTM'].fit(padded_train, y_train_categorical, epochs=epoch, batch_size=BATCH_SIZE)\n",
    "            yhat1 = members['CNN_LSTM'].predict(padded_train, verbose=0)\n",
    "            yhat2 = members['CNN_LSTM'].predict(padded_test, verbose=0)\n",
    "        elif key=='CNN_GRU':\n",
    "\n",
    "            members['CNN_GRU'].fit(padded_train, y_train_categorical, epochs=epoch, batch_size=BATCH_SIZE)\n",
    "            yhat1 = members['CNN_GRU'].predict(padded_train,verbose=0)\n",
    "            yhat2 = members['CNN_GRU'].predict(padded_test,verbose=0)\n",
    "            \n",
    "        \n",
    "        if stack_Train is None:\n",
    "            stack_Train = yhat1\n",
    "        else:\n",
    "            stack_Train = dstack((stack_Train, yhat1))\n",
    "        \n",
    "        if stack_Test is None:\n",
    "            stack_Test = yhat2\n",
    "        else:\n",
    "            stack_Test = dstack((stack_Test, yhat2))\n",
    "            \n",
    "    stack_Train = stack_Train.reshape((stack_Train.shape[0], stack_Train.shape[1]*stack_Train.shape[2]))\n",
    "    stack_Test = stack_Test.reshape((stack_Test.shape[0], stack_Test.shape[1]*stack_Test.shape[2]))\n",
    "    return stack_Train, stack_Test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1655024956409,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "a0evcb_wRfxc"
   },
   "outputs": [],
   "source": [
    "for key in members:\n",
    "    for i in range(0, len(members[key].layers)-1):\n",
    "        members[key].layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1655024956410,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "qb-uzkW2fDn1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "SFold = StratifiedKFold(n_splits=10,  shuffle=True,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1655024956411,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "90MtDq81tUvC"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score, average='weighted'),\n",
    "           'recall' : make_scorer(recall_score, average='weighted'), \n",
    "           'f1_score' : make_scorer(f1_score, average='weighted')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1655024956411,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "T97BYK3_37Tw"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1655024956411,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "AcoSDj2gVegj"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196288,
     "status": "ok",
     "timestamp": 1655025152684,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "BMjCJ-OnT5iH",
    "outputId": "60bb8877-db5f-4660-9e82-34acd7ef02bb"
   },
   "outputs": [],
   "source": [
    "SVM_DIC={'Accurcy':[], 'Precision': [],'Recall':[],'F1':[]}\n",
    "LR_DIC={'Accurcy':[], 'Precision': [],'Recall':[],'F1':[]}\n",
    "RF_DIC={'Accurcy':[], 'Precision': [],'Recall':[],'F1':[]}\n",
    "SVM_DIC_Train={'Accurcy':[], 'Precision': [],'Recall':[],'F1':[],'SDAccurcy':[], 'SDPrecision': [],'SDRecall':[],'SDF1':[]}\n",
    "LR_DIC_Train={'Accurcy':[], 'Precision': [],'Recall':[],'F1':[], 'SDAccurcy':[], 'SDPrecision': [],'SDRecall':[],'SDF1':[]}\n",
    "RF_DIC_Train={'Accurcy':[], 'Precision': [],'Recall':[],'F1':[], 'SDAccurcy':[], 'SDPrecision': [],'SDRecall':[],'SDF1':[]}\n",
    "\n",
    "for i in range(0,1):\n",
    "\n",
    "\n",
    "    SFold = StratifiedKFold(n_splits=10,  shuffle=True,random_state=120)\n",
    "    stackX_Test=None\n",
    "    stackX_Train=None\n",
    "    stackX_Train,stackX_Test =stacked_dataset(members,padded_train, padded_test, y_train_categorical, stackX_Train, stackX_Test,BATCH_SIZE, epoch)\n",
    "    \n",
    "    \n",
    "    param_grid = {'C': [6,7,8,9,10,11,12,1,2,3,4,5]}\n",
    "    grid_search = GridSearchCV(estimator = SVC(), param_grid = param_grid, cv = SFold) \n",
    "    grid_search.fit(stackX_Train, y_train)\n",
    "\n",
    "    \n",
    "    model_SVM = grid_search.best_estimator_     \n",
    "    \n",
    "    scores_Train_SVM = cross_validate(model_SVM, stackX_Train, y_train, scoring=scoring,  cv=SFold)\n",
    "   \n",
    "    yhat_SVM=cross_val_predict(model_SVM,stackX_Test,y_test, cv=SFold)\n",
    "\n",
    "    SVM_DIC['Accurcy'].append(round(100*accuracy_score(y_test, yhat_SVM), 2))\n",
    "    SVM_DIC['Precision'].append(round(100*precision_score(y_test, yhat_SVM,average='weighted'), 2))\n",
    "    SVM_DIC['Recall'].append(round(100*recall_score(y_test, yhat_SVM, average='weighted'), 2))\n",
    "    SVM_DIC['F1'].append(round(100*f1_score(y_test, yhat_SVM, average='weighted') , 2))     \n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1655025154052,
     "user": {
      "displayName": "hager saleh",
      "userId": "04961961339784377923"
     },
     "user_tz": -120
    },
    "id": "hQC7iAeefDn3",
    "outputId": "334f438f-ed39-4cee-d53b-35d969b10c5d"
   },
   "outputs": [],
   "source": [
    "print(\"SVM Test\")\n",
    "ReultofTest=pd.DataFrame([])\n",
    "ReultofTest=ReultofTest.append({'AccuracyTest' : round(np.mean(SVM_DIC['Accurcy']),2),\n",
    "                                'PrecisionTest':round(np.mean(SVM_DIC['Precision']),2),\n",
    "             'RecallTest' : round(np.mean(SVM_DIC['Recall']),2),'F1Test':round(np.mean(SVM_DIC['F1']),2)}, ignore_index=True)\n",
    "\n",
    "ReultofTest.reindex(['AccuracyTest','PrecisionTest','RecallTest','F1Test'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Stacking.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
